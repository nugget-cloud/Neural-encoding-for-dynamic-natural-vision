{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for pairing the data and stimuli and visalising it\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "data_file_path = \"database\\derivatives\\Groenetal2022TemporalDynamicsECoG\\data\\sub-p01_tdedata.mat\"\n",
    "stimuli_folder_path = \"stimuli_subp0_1\"\n",
    "events_folder_path = \"database\\derivatives\\ECoGBroadband\\sub-p01\\ses-umcuiemu01\\ieeg\"\n",
    "\n",
    "# Load iEEG data\n",
    "mat_data = loadmat(data_file_path)\n",
    "ieeg_segments = mat_data['epochs_v']\n",
    "\n",
    "def create_paired_dataset(events_file):\n",
    "    # Load events.tsv\n",
    "    events_df = pd.read_csv(events_file, sep='\\t')\n",
    "    \n",
    "    # Pair iEEG data with visual stimuli\n",
    "    paired_data = []\n",
    "    for segment_index, row in events_df.iterrows():\n",
    "        if segment_index < ieeg_segments.shape[2]:  # Ensure the index is within bounds\n",
    "            segment = ieeg_segments[:, :, segment_index]\n",
    "            \n",
    "            # Load visual stimulus\n",
    "            stim_file_path = os.path.join(stimuli_folder_path, row['stim_file'])\n",
    "            stim_data = loadmat(stim_file_path)\n",
    "            visual_stimulus = stim_data['stimulus']\n",
    "            \n",
    "            paired_data.append((segment, visual_stimulus))\n",
    "    \n",
    "    return paired_data\n",
    "\n",
    "# Iterate over all events.tsv files and create paired dataset\n",
    "all_paired_data = []\n",
    "for events_file in os.listdir(events_folder_path):\n",
    "    if events_file.endswith(\"_events.tsv\"):\n",
    "        paired_data = create_paired_dataset(os.path.join(events_folder_path, events_file))\n",
    "        all_paired_data.extend(paired_data)\n",
    "\n",
    "# The variable all_paired_data now contains the paired iEEG data and visual stimuli\n",
    "print(f\"Total paired data: {len(all_paired_data)}\")\n",
    "print(all_paired_data[0][0].shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_paired_data(segment_data, index):\n",
    "    ieeg_data, visual_stimuli = segment_data\n",
    "    \n",
    "    # Access the 'images' field from the visual_stimuli\n",
    "    visual_stimuli_images = visual_stimuli['images'][0,0]\n",
    "    \n",
    "    # Ensure we have the correct data for visualization\n",
    "    if len(visual_stimuli_images.shape) == 3:\n",
    "        visual_stimuli_image = visual_stimuli_images[:, :, 0]  # Extracting the first image from the sequence\n",
    "    else:\n",
    "        visual_stimuli_image = visual_stimuli_images\n",
    "\n",
    "    # Visualize the iEEG data\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ieeg_data[0, :])  # Visualize the data from the first electrode for simplicity\n",
    "    plt.title(f\"iEEG Data - Segment {index}\")\n",
    "    \n",
    "    # Visualize the visual stimulus\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(visual_stimuli_image, cmap='gray')\n",
    "    plt.title(f\"Visual Stimulus - Segment {index}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first 5 paired segments\n",
    "for idx, segment in enumerate(all_paired_data[:5]):\n",
    "    visualize_paired_data(segment, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_visual_stimulus = all_paired_data[0][1]\n",
    "print(type(sample_visual_stimulus))\n",
    "if isinstance(sample_visual_stimulus, dict):\n",
    "    print(sample_visual_stimulus.keys())\n",
    "print(sample_visual_stimulus.shape)\n",
    "print(sample_visual_stimulus.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_paired_data(segment_data, index):\n",
    "    ieeg_data, visual_stimuli = segment_data\n",
    "    \n",
    "    # Access the 'images' field from the visual_stimuli\n",
    "    visual_stimuli_images = visual_stimuli['images'][0,0]\n",
    "    \n",
    "    # Ensure we have the correct data for visualization\n",
    "    if len(visual_stimuli_images.shape) == 3:\n",
    "        visual_stimuli_image = visual_stimuli_images[:, :, 0]  # Extracting the first image from the sequence\n",
    "    else:\n",
    "        visual_stimuli_image = visual_stimuli_images\n",
    "\n",
    "    # Visualize the iEEG data\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ieeg_data[0, :])  # Visualize the data from the first electrode for simplicity\n",
    "    plt.title(f\"iEEG Data - Segment {index}\")\n",
    "    \n",
    "    # Visualize the visual stimulus\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(visual_stimuli_image, cmap='gray')\n",
    "    plt.title(f\"Visual Stimulus - Segment {index}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first 5 paired segments\n",
    "for idx, segment in enumerate(all_paired_data[:5]):\n",
    "    visualize_paired_data(segment, idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "# Directory to save the images\n",
    "save_directory = \"images\"  # Replace with your desired directory\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "def save_stimuli_as_images(segment_data, index):\n",
    "    _, visual_stimuli = segment_data\n",
    "    \n",
    "    # Access the 'images' field from the visual_stimuli\n",
    "    visual_stimuli_images = visual_stimuli['images'][0,0]\n",
    "    \n",
    "    # If the data isn't 3D, we can't proceed\n",
    "    if len(visual_stimuli_images.shape) != 3:\n",
    "        print(f\"Segment {index} does not have a 3D visual stimulus. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Directory for this segment's images\n",
    "    segment_directory = os.path.join(save_directory, f\"segment_{index}\")\n",
    "    if not os.path.exists(segment_directory):\n",
    "        os.makedirs(segment_directory)\n",
    "    \n",
    "    # Save each frame as an image\n",
    "    for frame_idx, frame in enumerate(visual_stimuli_images.transpose(2, 0, 1)):\n",
    "        image_filename = os.path.join(segment_directory, f\"frame_{frame_idx}.png\")\n",
    "        imageio.imwrite(image_filename, frame)\n",
    "\n",
    "        print(f\"Image for Segment {index}, Frame {frame_idx} saved at {image_filename}.\")\n",
    "\n",
    "# Save images for the first 5 paired segments\n",
    "for idx, segment in enumerate(all_paired_data[:5]):\n",
    "    save_stimuli_as_images(segment, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "data_file_path = \"database\\derivatives\\Groenetal2022TemporalDynamicsECoG\\data\\sub-p01_tdedata.mat\"\n",
    "stimuli_folder_path = \"stimuli_subp0_1\"\n",
    "events_folder_path = \"database\\derivatives\\ECoGBroadband\\sub-p01\\ses-umcuiemu01\\ieeg\"\n",
    "\n",
    "# Load iEEG data\n",
    "mat_data = loadmat(data_file_path)\n",
    "ieeg_segments = mat_data['epochs_v']\n",
    "\n",
    "def create_paired_dataset(events_file):\n",
    "    # Load events.tsv\n",
    "    events_df = pd.read_csv(events_file, sep='\\t')\n",
    "    \n",
    "    # Pair iEEG data with visual stimuli\n",
    "    paired_data = []\n",
    "    for segment_index, row in events_df.iterrows():\n",
    "        if segment_index < ieeg_segments.shape[2]:  # Ensure the index is within bounds\n",
    "            segment = ieeg_segments[:, :, segment_index]\n",
    "            \n",
    "            # Load visual stimulus\n",
    "            stim_file_path = os.path.join(stimuli_folder_path, row['stim_file'])\n",
    "            stim_data = loadmat(stim_file_path)\n",
    "            visual_stimulus = stim_data['stimulus']\n",
    "            \n",
    "            paired_data.append((segment, visual_stimulus))\n",
    "    \n",
    "    return paired_data\n",
    "\n",
    "# Iterate over all events.tsv files and create paired dataset\n",
    "all_paired_data = []\n",
    "for events_file in os.listdir(events_folder_path):\n",
    "    if events_file.endswith(\"_events.tsv\"):\n",
    "        paired_data = create_paired_dataset(os.path.join(events_folder_path, events_file))\n",
    "        all_paired_data.extend(paired_data)\n",
    "\n",
    "# Batch processing\n",
    "BATCH_SIZE = 1  # Define a suitable batch size\n",
    "current_batch = 0\n",
    "batch_start = 0\n",
    "\n",
    "while batch_start < len(all_paired_data):\n",
    "    # Extract batch\n",
    "    batch_data = all_paired_data[batch_start: batch_start + BATCH_SIZE]\n",
    "    \n",
    "    # Prepare data\n",
    "    X_batch = [item[0] for item in batch_data]\n",
    "    y_batch_images = [item[1]['images'] for item in batch_data]\n",
    "\n",
    "    # Convert and normalize the data\n",
    "    X_batch = [item.astype('float32') for item in X_batch]\n",
    "    y_batch_normalized = []\n",
    "\n",
    "    for image_sequence in y_batch_images:\n",
    "    # Check if the current sequence is indeed an image sequence\n",
    "        if len(image_sequence.shape) == 3: \n",
    "            normalized_sequence = (image_sequence / 255.0).astype('float32')\n",
    "            y_batch_normalized.append(normalized_sequence)\n",
    "        else:\n",
    "        # Handle the case when it's not a straightforward image sequence\n",
    "        # For now, we'll just append the original sequence, but you might want to inspect it further\n",
    "          y_batch_normalized.append(image_sequence)\n",
    "\n",
    "    y_batch_images = y_batch_normalized\n",
    "\n",
    "    # Reshape for neural network\n",
    "    X_batch = [np.reshape(item, (item.shape[0], item.shape[1], 1)) for item in X_batch]\n",
    "    \n",
    "    # Save processed batch to disk\n",
    "    np.savez(f'processed_data_batch_{current_batch}.npz', X=X_batch, y=y_batch_images)\n",
    "    \n",
    "    # Update counters\n",
    "    batch_start += BATCH_SIZE\n",
    "    current_batch += 1\n",
    "\n",
    "print(f\"Processed {current_batch} batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model training but this one does not take any batches\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape, Dense\n",
    "\n",
    "# # Load the batched data\n",
    "# def load_data_from_files(directory, num_files):\n",
    "#     all_X, all_y = [], []\n",
    "#     for idx in range(num_files):\n",
    "#         file_path = os.path.join(directory, f'processed_data_batch_{idx}.npz')\n",
    "#         data = np.load(file_path, allow_pickle=True)  # Allow loading object arrays\n",
    "#         all_X.append(data['X'])\n",
    "#         all_y.append(data['y'])\n",
    "    \n",
    "#     return np.vstack(all_X), np.vstack(all_y)\n",
    "\n",
    "\n",
    "# # Load data\n",
    "# X, y = load_data_from_files('batch', 107)  # Replace '/path_to_directory/' with the actual path\n",
    "\n",
    "# # Model definition\n",
    "# model = Sequential([\n",
    "#     Conv1D(64, kernel_size=3, activation='relu', padding='valid', input_shape=(288, 665)),\n",
    "#     MaxPooling1D(2),\n",
    "#     Conv1D(128, kernel_size=3, activation='relu', padding='valid'),\n",
    "#     MaxPooling1D(2),\n",
    "#     Conv1D(256, kernel_size=3, activation='relu', padding='valid'),\n",
    "#     UpSampling1D(2),\n",
    "#     Conv1D(128, kernel_size=3, activation='relu', padding='valid'),\n",
    "#     UpSampling1D(2),\n",
    "#     Flatten(),\n",
    "#     Dense(1030*1030, activation='sigmoid'),  # This should match the dimensions of your images (1030 x 1030)\n",
    "#     Reshape((1030, 1030))\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Save the model\n",
    "# model.save('trained_model.h5')\n",
    "\n",
    "# print(\"Model trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape, UpSampling1D\n",
    "\n",
    "def data_generator(num_files, batch_size=32):\n",
    "    for idx in range(num_files):\n",
    "        file_path = f'batch/processed_data_batch_{idx}.npz'\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        X = np.array(data['X']).reshape(-1, 288, 665)  # Ensure X retains its 3D shape\n",
    "        \n",
    "        # Convert object array to float array and reshape to have a 4D tensor\n",
    "        y_array = np.array(data['y'].tolist()).reshape(-1, 1030, 1030, 1)\n",
    "        \n",
    "        y_resized = tf.image.resize(y_array, (128, 128))  # Resize target images to match model output\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            end = start + batch_size\n",
    "            yield X[start:end], y_resized[start:end]\n",
    "\n",
    "\n",
    "# Model definition\n",
    "model = Sequential([\n",
    "    Conv1D(16, kernel_size=3, activation='relu', input_shape=(288, 665)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128*128, activation='sigmoid'),  # Reduced output size\n",
    "    Reshape((128, 128))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Estimate the number of steps per epoch\n",
    "steps_per_epoch = sum(len(np.load(f'batch/processed_data_batch_{i}.npz', allow_pickle=True)['X']) for i in range(107)) // 32\n",
    "\n",
    "# Train the model using the generator\n",
    "model.fit(data_generator(107), epochs=10, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "model.save('trained_model.h5')\n",
    "print(\"Model trained and saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Original image\n",
    "original_img = tf.reshape(y_test_resized[0], (128, 128)).numpy()  # Using the first image from the resized test set\n",
    "predicted_img = y_pred[0]  # Since y_pred has shape (1, 128, 128), y_pred[0] will have shape (128, 128)\n",
    "\n",
    "mse = mean_squared_error(original_img, predicted_img)\n",
    "\n",
    "# Visualize the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "ax[0].imshow(original_img, cmap='gray')\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')\n",
    "    \n",
    "ax[1].imshow(predicted_img, cmap='gray')\n",
    "ax[1].set_title(\"Predicted Image\")\n",
    "ax[1].axis('off')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(f\"MSE between the images: {mse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is bit complex and with no batches\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from scipy.io import loadmat\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Paths\n",
    "# data_file_path = \"database\\derivatives\\Groenetal2022TemporalDynamicsECoG\\data\\sub-p01_tdedata.mat\"\n",
    "# stimuli_folder_path = \"stimuli_subp0_1\"\n",
    "# events_folder_path = \"database\\derivatives\\ECoGBroadband\\sub-p01\\ses-umcuiemu01\\ieeg\"\n",
    "\n",
    "# # Load iEEG data\n",
    "# mat_data = loadmat(data_file_path)\n",
    "# ieeg_segments = mat_data['epochs_v']\n",
    "\n",
    "# def create_paired_dataset(events_file):\n",
    "#     # Load events.tsv\n",
    "#     events_df = pd.read_csv(events_file, sep='\\t')\n",
    "    \n",
    "#     # Pair iEEG data with visual stimuli\n",
    "#     paired_data = []\n",
    "#     for segment_index, row in events_df.iterrows():\n",
    "#         if segment_index < ieeg_segments.shape[2]:  # Ensure the index is within bounds\n",
    "#             segment = ieeg_segments[:, :, segment_index]\n",
    "            \n",
    "#             # Load visual stimulus\n",
    "#             stim_file_path = os.path.join(stimuli_folder_path, row['stim_file'])\n",
    "#             stim_data = loadmat(stim_file_path)\n",
    "#             visual_stimulus = stim_data['stimulus']\n",
    "            \n",
    "#             paired_data.append((segment, visual_stimulus))\n",
    "    \n",
    "#     return paired_data\n",
    "\n",
    "# # Iterate over all events.tsv files and create paired dataset\n",
    "# all_paired_data = []\n",
    "# for events_file in os.listdir(events_folder_path):\n",
    "#     if events_file.endswith(\"_events.tsv\"):\n",
    "#         paired_data = create_paired_dataset(os.path.join(events_folder_path, events_file))\n",
    "#         all_paired_data.extend(paired_data)\n",
    "\n",
    "# # Reshape the iEEG data\n",
    "# ieeg_data = [segment_data[0].T for segment_data in all_paired_data]\n",
    "# visual_stimuli_data = [segment_data[1] for segment_data in all_paired_data]\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train_images, y_test_images = train_test_split(ieeg_data, visual_stimuli_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Convert and normalize the data\n",
    "# X_train = [item.astype('float32') for item in X_train]\n",
    "\n",
    "# # Convert and normalize y_train_images\n",
    "# y_train_processed = []\n",
    "# for item in y_train_images:\n",
    "#     if not isinstance(item, np.ndarray):\n",
    "#         item = np.array(item)\n",
    "#     y_train_processed.append(item.astype('float32') / 255.0)\n",
    "# y_train_images = y_train_processed\n",
    "\n",
    "# X_test = [item.astype('float32') for item in X_test]\n",
    "\n",
    "# # Convert and normalize y_test_images\n",
    "# y_test_processed = []\n",
    "# for item in y_test_images:\n",
    "#     if not isinstance(item, np.ndarray):\n",
    "#         item = np.array(item)\n",
    "#     y_test_processed.append(item.astype('float32') / 255.0)\n",
    "# y_test_images = y_test_processed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
